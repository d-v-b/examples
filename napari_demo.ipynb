{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Napari demo\n",
    "#### About napari\n",
    "Napari is an open-source python/Qt-based image viewer developed by developers at or affiliated with the Chan Zuckerberg Institute (CZI), as well as volunteers. Napari targets users viewing and analyzing imaging data in python. It is approximately 1 year old, and is very actively developed, as one can see from their [github](https://github.com/napari/napari) repo.  \n",
    "\n",
    "Napari is available on pip, and can be installed via `pip install napari`  \n",
    "\n",
    "Napari is not browser-based; it is not a widget that can be embedded in a notebook. It requires a desktop environment to run, so if you want to use napari on a remote system be sure you have a remote desktop environment set up (e.g., nomachine).\n",
    "\n",
    "#### This notebook\n",
    "\n",
    "This notebook will use a toy workflow (generating fake functional imaging data) to demonstrate how to use napari, as well as its limitations. This demo assumes that the user has a recent version of python and the standard python scientific computing stack installed (e.g., `numpy`, `scipy`, `dask`, `matplotlib`). Although it wasn't my original intention, I used napari heavily during the creation of this tutorial. I had to pick a bunch of parameters for the simulated data, and since the data is 4D, I needed an image viewer that worked with that number of dimensions. Using napari was _much_ faster than the alternatives (one plane at a time via matplotlib, or saving files to disk and viewing them with fiji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage of napari in the notebook:\n",
    "\n",
    "Import napari and it's ready to use... with a caveat. In the notebook, we have to add this `%gui qt` thing.\n",
    "\n",
    "The order of these operations matters -- `%matplotlib inline` should occur before `%gui qt`. I don't know why exactly. Generally, using Qt-based gui tools (like napari and matplotlib) in the jupyter environment can require strange stuff like this to avoid hiccups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import napari\n",
    "# this line is necessary to have non-blocking code in the notebook:\n",
    "%gui qt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use napari to display some random data by creating a `Viewer` and calling the `add_image` method, or by calling `view_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a viewer, add images later\n",
    "v = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v.add_image(np.random.random_sample(size=(10,10,10,3)), rgb=True, name='Random floats (rgb)')\n",
    "\n",
    "# create a viewer and display an image\n",
    "napari.view_image(np.random.randint(0,255, size=(10,10,10,10,10)),name='Random integers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy workflow: creating fake functional imaging data\n",
    "In this workflow, we will generate a simple fake functional imaging dataset, which consists in the following operations:\n",
    "* Create smooth timeseries (one per cell)\n",
    "* Create a cell \n",
    "* Fill the 4D (time, z ,y , x) volume with time-varying cells and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensionality of the data; shrink in x and y on weaker computers\n",
    "t,z,y,x = 100, 32, 1024, 2048 \n",
    "\n",
    "# scaling necessary for isotropic voxel sizes\n",
    "# assume 4 micron z step, .625 micron y and x size\n",
    "scale = (1, 4, .625, .625) \n",
    "\n",
    "# the number of cells we want\n",
    "num_cells = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space\n",
    "Here we initialize our anatomical volume, create a cell, and fill the volume with cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "from skimage.morphology import ball\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "vol = np.zeros((z,y,x), dtype='uint16')\n",
    "# Randomly pick unique locations for cells\n",
    "cellpos = np.random.choice(np.prod(vol.shape), size=num_cells, replace=False)\n",
    "# stick 1's where the cells will go\n",
    "vol.ravel()[cellpos] = 1\n",
    "\n",
    "# set the radius of the cell\n",
    "cell_radius = 14\n",
    "base_cell = ball(cell_radius)\n",
    "# squish the cell in z, according to the anisotropy of our data\n",
    "cell = zoom(base_cell.astype('float32'), (scale[2] / scale[1], 1, 1))\n",
    "\n",
    "# use convolution to stick cells in all the right places\n",
    "anatomy = fftconvolve(vol.astype('float32'), cell, mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a bunch of 3D arrays. It would be good to inspect them before we move on to the next part of the workflow. Here I add a bunch of our intermediate images to the active napari viewer so we can get a look at what we just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_image(base_cell, name=\"Isotropic cell\", contrast_limits=(0,1))\n",
    "v.add_image(cell, name=\"Squished cell\", contrast_limits=(0,1))\n",
    "v.add_image(anatomy, name=\"Anatomy\", scale = scale[1:], contrast_limits=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time\n",
    "We want our cells to have some temporal dynamics; here we create a function that generates simple smooth signals by smoothly interpolating a short binary sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def random_smooth_vector(num_points=5):\n",
    "    return interp1d(np.linspace(0,1,num_points), np.random.randint(0,2, size=(num_points)), kind='cubic')\n",
    "\n",
    "timeseries = np.array([random_smooth_vector()(np.linspace(0,1,t)) for p in cellpos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our timeseries look reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12,4), sharex=True, dpi=200)\n",
    "axs[0].plot(timeseries[0]);\n",
    "axs[1].imshow(timeseries, aspect='auto')\n",
    "axs[0].title.set_text('Sample')\n",
    "axs[1].title.set_text('All timeseries')\n",
    "[ax.set_xlabel('Time') for ax in axs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space + Time\n",
    "Now that we have our timeseries and anatomy, we can put them together. I do this with a function that takes intensities, positions, an output shape, and a cell volumes and returns a 3D volume with some multiplicative, then additive, noise (which emulates imaging conditions). Note that I use `dask.delayed` here to make the function _lazy_. This lets me parallelize the computation of the full dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "@delayed\n",
    "def make_timepoint(intensities, cellpos, shape, cell):\n",
    "    vol = np.zeros(shape, dtype='float32')\n",
    "    vol.ravel()[cellpos] = intensities # put intensities in the right place    \n",
    "    convolved = fftconvolve(vol, cell, mode='same') # spread out intensities\n",
    "    convolved *= (15 + np.random.standard_normal(size=convolved.shape).astype('float32') ) # multiplicative noise\n",
    "    convolved += np.random.poisson(90, size=convolved.shape).astype('uint16') # additive noise\n",
    "    return convolved.astype('uint16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out a sample timepoint\n",
    "Before computing the entire dataset, we should compute a single timepoint and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = make_timepoint(intensities=timeseries[:,3], cellpos=cellpos, shape=(z,y,x), cell=cell).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_image(test, name ='Test timepoint', scale=scale[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute entire dataset\n",
    "If that single timepoint looks good, we can go ahead and use the `make_timepoint` function to define an entire 4D volume (lazily, using dask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "dataset = da.stack([da.from_delayed(make_timepoint(timeseries[:,t_], cellpos, (z,y,x), cell), shape=(z,y,x), dtype='uint16') for t_ in range(t)])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a little big, so I set up a local dask cluster to transparently scale out the computation of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client, LocalCluster\n",
    "cl = Client(LocalCluster(host=''))\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = dataset.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data and get ROI\n",
    "In addition to the image layer we have been using for viewing images, napari has a \"shapes\" layer that allows you to annotate a region with different shapes. We will draw some shapes and use them to get ROI timeseries from our full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.view_image(result, scale=scale[1:])\n",
    "shapes = v.add_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot is the natural way to display a timeseries. Napari can't display line plots, but it gives us enough information to do it ourselves with matplotlib. All we need is a function that converts the coordinates of a shape into an index into our data. This is super easy for rectangular ROI; for circular ROI, the function would need to be a little more sophisticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a set of points defining a rectangular ROI to a tuple of slices.\n",
    "def rectToSlices(points, scaling):\n",
    "        pts = (points / scaling).astype('int')                \n",
    "        start, stop =  pts.min(0), 1 + pts.max(0)\n",
    "        results = tuple(slice(a,b) for a,b in zip(start, stop))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function, we can grab the data under the areas where we drew our ROI and plot the mean timeseries in matplotlib. Here I use a static, inline plot, but I'm pretty sure you could write a dynamic plot that updates whenever the shapes in the napari viewer are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [rectToSlices(d, np.array(scale)) for d in shapes.data]\n",
    "fig, axs = plt.subplots(figsize=(12,4), dpi=200)\n",
    "for ind,sl in enumerate(slices):\n",
    "    axs.plot(result[:, sl[1], sl[2], sl[3]].mean((1,2,3)), label=f'ROI {ind}')\n",
    "axs.set_xlabel('Time')\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "* Use napari for visualizing your images.\n",
    "* Napari is changing rapidly, so don't get too comfortable with certain details.\n",
    "* If you have problems / features you want added, talk to me or raise issues at https://github.com/napari/napari/issues. The napari team is very responsive.\n",
    "* Missing features (as of napari v0.2.8) : non-orthogonal slicing, a proper coordinate space model, proper lazy image loading. But this stuff will get added eventually, I hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
